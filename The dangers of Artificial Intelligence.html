<!DOCTYPE html>
<html>
<head>
	<title>The dangers of Artificial Intelligence
</title>
</head>
<body>
	<h1>The dangers of Artificial Intelligence
</h1>
	<h2>links</h2>
	<ul>
  <li><a href="index.html">Main page</a></li>
  <li><a href="What is Artificial Intelligence.html">What is Artificial Intelligence?</a></li>
  <li><a href="how artificial intelligence will change the world in future.html">How artificial intelligence will change the world in future?</a></li>
   <li><a href="applications on Artificial Intelligence.html">Applications on Artificial Intelligence</a></li>
    <li><a href="The dangers of Artificial Intelligence.html">The dangers of Artificial Intelligence</a></li>

</ul>
When seeing this headline, many AI researchers roll their eyes: "Stephen Hawking warns that the rise of robots may be disastrous for mankind." And as many have lost count of how many similar articles they've seen. These articles are usually accompanied by a robot of evil appearance carrying a sword,And they suggest that we should worry about the rising and killing of robots, because they have become conscious and/or evil. Such articles are, in fact, quite impressive on a lighter note, because they summarize the scenario that AI researchers are not concerned about. That scenario brings together as many as three distinct misconceptions: concern for consciousness, evil, and robots.
You have a subjective view of colors, sounds, etc. while driving down the lane. But is there a subjective experience to a self-driving car? Does being a self-driving car actually feel like anything at all? Though this mystery of consciousness is in its own right interesting, it is irrelevant to the risk of AI. If you find yourself hit by a driverless car,
it makes no difference to you whether it subjectively feels conscious. In the same way, what will affect us humans is what superintelligent AI does, not how it subjectively feels.Another red herring is the fear of machines which turn evil. The real worry is not malevolence but skill. By definition, a superintelligent AI is very good at achieving its goals, no matter what they may be
But we have to make sure the priorities match with ours. Generally speaking, humans don't hate ants but we're smarter than they are â€“ so if we want to build a hydroelectric dam and there's an anthill there, too bad for the ants. The Beneficial-AI movement wants to avoid putting humanity in those ants' position.
</body>
</html>
